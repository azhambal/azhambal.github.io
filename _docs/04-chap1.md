---
title: "Введение"
permalink: /book/chap1/
excerpt: "Введение."
last_modified_at: 2021-06-07T08:48:05-04:00
toc: true
---
Зрительная система человека является одним из чудес света. Рассмотрим следующую последовательность рукописных цифр:

![image-center]({{ "/assets/images/digits.png" | relative_url }}){: .align-center}

Большинство людей без особой сложности распознают эти цифры, как 5, 0, 4, 1, 9 и 2. Но эта легкость обманчива. В каждом полушарии мозга человека имеется первичная зрительная кора, также известная, как зрительная зона V1, которая содержит 140 миллионов нейронов с десятками миллиардов связей между ними. Но в обработке зрительного сигнала участвует не только зона V1, но также целая группа зрительных зон – V2, V3, V4 и V5, что делает обработку изображений более сложным процессом. В наших головах находится суперкомпьютер, настроенный эволюцией на протяжении сотен миллионов лет, который отлично приспособлен понять видимый мир. Распознавать рукописные цифры не так легко. Однако у нас, людей, поразительно хорошо получается распознавать то, что видят наши глаза. Но почти вся эта работа проходит бессознательно. И поэтому мы обычно не понимаем того, насколько трудную задачу решает наша зрительная система.

Сложность визуального распознавания образов становится очевидной, если вы попытаетесь написать компьютерную программу для распознавания цифр, как те, что выше. То, что кажется легким, когда мы делаем это сами, вдруг становится крайне сложным. Простых рассуждений о том, как мы понимаем формы: «цифра 9 имеет петлю в верхней части, и вертикальный штрих в правом нижнем углу» – это не так просто для алгоритмического выражения. При попытке описать точный алгоритм, вы можете быстро попасть в трясину исключений, оговорок и особых случаев. Такое решение кажется безнадежным.

Нейронные сети используют другой подход. Идея заключается в том, чтобы получить большое количество рукописных цифр, называемых обучающей выборкой, а затем разработать систему, которая может обучиться на этой выборке. Другими словами, нейронная сеть использует примеры, чтобы автоматически выводить правила для распознавания рукописных цифр. Кроме того, за счет увеличения количества обучающей выборке, сеть может узнать больше о почерке, и таким образом повысить его точность. Таким образом, если я использовал более 100 цифр для обучения, возможно, вы могли бы построить лучший распознаватель рукописного ввода, используя тысячи или даже миллионы и миллиарды обучающих примеров

![image-center]({{ "/assets/images/mnist_100_digits.png" | relative_url }}){: .align-center}

В этой главе мы напишем программу, реализующую нейронную сеть, которая учится распознавать рукописные цифры. Программа имеет длину всего в 74 строки, а также не использует никаких специальных библиотек нейронных сетей. Но эта короткая программа может распознавать цифры с точностью более чем в 96 процентах без вмешательства человека. Кроме того, в последующих главах мы будем развивать идеи, которые могут улучшить точность до более чем 99 процентов. На самом деле, лучшие коммерческие нейронные сети в настоящее время настолько хороши, что они используются банками для обработки чеков и почтовыми отделениями для распознавания адреса.

Мы сфокусируемся на распознавании рукописного текста, поскольку это отличный прототип задачи для изучения нейронных сетей в целом. Это отличный пример: достаточно сложный (распознать приписные цифры – это достижение), но и не требующий невероятно сложного решения или больших вычислительных мощностей. Кроме того, это отличный способ изучить более продвинутые методы, такие как глубокое обучение. И на всем протяжении книги мы будем неоднократно возвращаться к проблеме распознавания рукописного текста. Позже в книге, мы обсудим, как эти идеи могут быть применены к другим проблемам в области компьютерного зрения, а также в речи, обработке естественного языка и других областях.

Конечно, если целью главы было только написание компьютерной программы для распознавания рукописных цифр, то глава была бы намного короче. Но ходу главы мы будем развивать многие основополагающие идеи о нейронных сетях, в том числе упомянем о двух важных типах искусственного нейрона (перцептрон и сигмоидальный нейрон), а также о стандартном алгоритме обучения для нейронных сетей, известном как стохастический градиентный спуск.

## Перцептрон

Что такое нейронная сеть? Для начала я расскажу о типе искусственного нейрона, имя которому – перцептрон. Перцептрон был создан в 1950-х годах ученым Фрэнком Розенблаттом, вдохновленным более ранними работами Уоррена Мак-Каллока и Уолтера Питтса. Сегодня чаще используются другие модели искусственных нейронов – в этой книге и в других многих современных работах по нейронным сетям, в основном, используется модель нейрона, называемая сигмоидальным нейроном. Мы доберемся до сигмоидальных нейронов в ближайшее время. Но чтобы понять, почему сигмоидальные нейроны определены так, как они есть, стоит потратить время, чтобы сначала понять, что представляют из себя перцептроны.

Так как работает перцептрон? Перцептрон берет несколько бинарных входов $$x_1, x_2, ...$$, и производит один бинарный выход:

![image-center]({{ "/assets/images/tikz0.png" | relative_url }}){: .align-center}

В примере, показанном выше, перцептрон имеет три входа $$x_1$$,$$x_2$$,$$x_3$$. В общем случае, он может иметь больше или меньше число входов. Розенблатт предложил простое правило для вычисления выходного сигнала. Он ввел веса, $$w_1, w_2, ...$$, вещественные числа, выражающие значение соответствующих входов на выход. Нейрон имеет бинарный выход ($$0$$ или $$1$$), определенный взвешенной суммой $$\sum_{j} w_j x_j$$, которая больше или меньше некоторого порогового значения. Точно также, как и веса, пороговое значение будет вещественным числом, которое является параметром нейрона. В более строгом алгебраическом смысле имеем:

$$\text{выход} = \begin{cases}
 & 0 \text{, если } \sum_{j} w_j x_j <= \text{порогового значения}\\ 
 & 1 \text{, если } \sum_{j} w_j x_j > \text{порогового значения} 
\end{cases}$$

И это всё, что вам нужно знать о том, как работает перцептрон!

Это базовая математическая модель. Таким образом, вы можете считать, что перцептрон – это устройство, которое принимает решения путем взвешивания доказательств. Позвольте мне привести пример. Это не очень реалистичный пример, однако доступный для понимания, и мы скоро доберемся до более реалистичных примеров. Предположим, что скоро выходные дни, и вы слышали, что в вашем городе пройдет фестиваль сыра. Вы любите сыр, и пытаетесь решить, стоит ли идти на фестиваль. Вы могли бы принять решение путем взвешивания трех факторов:

1. Будет ли погода хорошей?
2. Пойдут ли с вами ваши друзья?
3. Доступен ли проезд до мероприятия общественным транспортом?

Мы можем представить эти три фактора с помощью соответствующих бинарных переменных $$x_1$$, $$x_2$$ и $$x_3$$. Для примера, $$x_1=1$$ если погода будет хорошей, и $$x_1=0$$ если погода будет плохой. По аналогии, $$x_2=1$$ если с вами идут друзья, и $$x_2=0$$ если не идут. Подобным образом обозначим $$x_3$$ и доступность общественного транспорта.

Теперь предположим, что вы обожаете сыр так, что вы рады идти на фестиваль, даже если ваши друзья в этом не заинтересованы и до фестиваля будет трудно добраться. Но, возможно, вы действительно не любите плохую погоду, и нет никаких причин идти на фестиваль при плохой погоде. Вы можете использовать перцептрон для моделирования принятий решений такого рода. Одним вариантов будет выбор веса $$w_1=6$$ для погоды, для остальных условий веса будут равны $$w_2=2$$ и $$w_3=2$$. Большее значение веса $$w_1$$ означает, что погода важнее для вас, чем транспортная доступность или то,  пойдут ли друзья с вами. Наконец, предположим, что вы выбрали порогое значение $$5$$ для перцептрона. С помощью выбранных значений, перцептрон реализует требуемую модель принятия решений, выводя $$1$$ всякий раз, когда погода хорошая, и $$0$$, когда погода плохая. На выход такой модели не влияет то, хотят ли ваши друзья идти или то, что до фестиваля можно будет добраться на общественном транспорте.

Путем изменения весов и порогового значения, мы можем получить различные модели принятия решений. Например, предположим, что мы выберем пороговое значение равное $$3$$. Тогда перцептрон решит, что вы должны идти на фестиваль всякий раз, когда на улице хорошая погода, или когда до фестиваля можно добраться общественным транспортом и ваши друзья идут с вами. Другими словами, это была бы другая модель принятия решений. Опуская пороговое значение, вы в большей степени готовы идти на фестиваль.
Очевидно, что перцептрон не является полной моделью принятия решений человеком! Но пример иллюстрирует, как перцептрон может взвешивать различные виды доказательств для того, чтобы принимать решения. И кажется вероятным, что сложная сеть перцептронов может находить очень искусные решения.

![image-center]({{ "/assets/images/chap1-1.png" | relative_url }}){: .align-center}

В этой сети, первый столбец персептронов – то, что мы будем называть первым слоем перцептронов выводит три очень простых решения, путем взвешивания входных данных. Что можно сказать о персептронах во втором слое? Каждый из этих персептронов принимает решение путем взвешивания результатов первого слоя. Таким образом, перцептрон во втором слое может принять решение на более сложном и более абстрактном уровне, чем персептроны первого слоя. И еще более сложные решения принимаются перцептроном в третьем слое. Таким образом, многослойная сеть перцептронов может участвовать в принятии сложных решений.

В определении перцептрона указано, что у него только один выход. Однако, на картинке выше перцептроны выглядят так, как будто у них имеется несколько выходов. Но на самом деле выход один. Многочисленные стрелки выхода – лишь способ указания на то, что выход из перцептрона используется в качестве входных данных для нескольких других перцептронов. Этот способ менее громоздкий, чем рисование одной расщепляющейся выходной линии.

Давайте упростим способ описания перцептрона. Условие $$\sum_{j} w_j x_j > \text{порогового значения}$$ является громоздким, и мы можем добавить два обозначения для его упрощения. Первым обозначением будет написание суммы $$\sum_{j} w_j x_j$$ как скалярного произведения векторов $$w$$ и $$x$$. $$w\cdot x=\sum_{j} w_j x_j$$, где $$w$$ и $$x$$ – векторы, компоненты которых веса и входы соответственно. Второе изменение заключается в переходе порогового значения на другую сторону неравенства, и замена его на то, что можно назвать смещением перцептрона, $$b\equiv$$ - пороговое значение. Используя обозначение смещения вместо порогового значения, можно привести уравнение перцептрона к виду:

$$\text{выход} = \begin{cases}
 & 0 \text{, если } w\cdot x + b <=0\\ 
 & 1 \text{, если } w\cdot x + b >0 
\end{cases}$$

Вы можете считать, что смещение является мерой того, насколько легко заставить перцептрон выдать $$1$$. Или, выражаясь в биологических терминах, смещение показывает насколько легко активировать перцептрон. Перцептрону с действительно большим смещением очень легко выдать $$1$$. Но если смещение отрицательное, получить на выходе $$1$$ будет сложнее. Очевидно, что введение смещения, это лишь небольшое изменение в описании перцептрона, но, как мы увидим позднее, оно приведет к упрощению нотации в будущем. Поэтому в оставшейся части книги мы не будем использовать термин «пороговое значение».

Выше я описывал перцептрон как метод для принятия решений, использующий метод взвешивания доказательств. Другой подход состоит в том, чтобы использовать перцептрон для вычисления элементарных логических функций, таких как «И», «ИЛИ», штрих Шеффера («И-НЕ»). Например, предположим, что мы имеем перцептрон с двумя входами, каждый с весом $$-2$$ и смещением $$3$$:

![image-center]({{ "/assets/images/chap1-2.png" | relative_url }}){: .align-center}

Тогда мы видим, что вход $$x_1=0$$, $$x_2=0$$ на выходе дает $$1$$, так как $$(-2)*0+(-2)*0+3=3$$ (положительное число). Здесь я ввел символ $$*$$, чтобы показать умножением явным. Подобные расчеты демонстрируют, что входы $$(0,1), (1,0)$$ на выходе дают $$1$$. Но вход $$(1,1)$$ имеет выход равный $$0$$, поскольку $$(-2)*1+(-2)*1+3=-1$$ (отрицательное число). Поэтому можно сказать, что такой перцептрон реализует логический элемент – штрих Шеффера

Пример со штрихом Шеффера показывает, что мы можем использовать перцептроны для вычисления простых логических функций. На самом деле, мы можем использовать сети перцептронов для вычисления любой логической функции вообще. Причиной является то, что штрих Шеффера образует базис для пространства булевых функций от двух переменных, то есть используя только штрих Шеффера можно построить остальные операции. Например, мы можем использовать штрих Шеффера для того, чтобы построить схему, которая суммирует два бита: $$x_1$$, $$x_2$$. Для этого требуется вычислить побитовую сумму, $$x_1\bigoplus x_2$$, а также бит переноса, который установлен в положение $$1$$, когда оба бита $$x_1$$ и $$x_2$$ равны $$1$$, то есть бит переноса является просто значением $$x_1 x_2$$:

![image-center]({{ "/assets/images/chap1-3.png" | relative_url }}){: .align-center}

Для получения эквивалентной сети перцептронов мы заменим все штрихи Шеффера на перцептроны с двумя входами, каждый с весом $$-2$$ и общим отклонением $$3$$. Сеть представлена на рисунке ниже. Обратите внимание, что я немного переместил перцептрон, соответствующий нижнему узлу, просто для удобства отображения:

![image-center]({{ "/assets/images/chap1-4.png" | relative_url }}){: .align-center}

Примечательной особенностью этой сети перцептронов является то, что выход из крайнего левого перцептрона используется дважды в качестве входных данных для самого нижнего перцептрона. Когда я определил модель перцептрона, я не сказал, может ли разрешен такой двойной выход из одного и того же места. На самом деле, это не имеет особого значения. Если мы не хотим принимать подобные допущения, то можно просто объединить две строки в одно соединение с весом $$-4$$ вместо двух соединений с весом $$-2$$ (если вам не понятна очевидность этой мысли, попробуйте доказать это самостоятельно). С учетом этих изменений, сеть будет выглядеть следующим образом, где все немаркированные веса равны $$-2$$, все смещения равны $$3$$, одиночный вес равен $$-4$$, как показано на рисунке:

![image-center]({{ "/assets/images/chap1-5.png" | relative_url }}){: .align-center}

До сих пор я рисовал входы $$x_1$$ и $$x_2$$ как переменные, находящиеся слева от сети перцептронов. На самом деле, мы можем добавить еще один дополнительный слой перцептронов – входной слой для кодирования входов:

![image-center]({{ "/assets/images/chap1-6.png" | relative_url }}){: .align-center}

Это сокращенное обозначение входных перцептронов, которые имеют выход, но не имеют входа. На самом деле, это не означает, что перцептрон не содержит никаких входов. Чтобы убедиться в этом, предположим, что мы имеем перцептрон без каких-либо входов. Тогда взвешенная сумма $$\sum_{j} w_j x_j$$ будет всегда равна нулю, и перцептрон будет всегда выводить $$1$$ если $$b>0$$, и $$0$$ при $$b<=0$$. Таким образом, перцептрон всегда будет выводить фиксированное, а не желаемое значение ( $$x_1$$, в примере выше). Лучше думать о входных перцептронах не как о перцептронах вообще, а как о специальных элементах, которые определены для вывода требуемых значений: $$x_1, x_2, ...$$.

Пример с сумматором демонстрирует, как сеть перцептронов может использоваться для построения схемы, состоящей из множества логических элеметов штрих Шеффера. Поскольку штрих Шеффера является базисом в пространстве булевых функций, то отсюда следует возможность построения универсальных вычислений при помощи перцептрона.

Вычислительная универсальность перцептронов одновременно обнадеживает и разочаровывает. Обнадеживает, потому что сети перцептронов могут быть такими же мощными, как и любые вычислительные устройства. А разочаровывает, поскольку кажется, что перцептрон – всего лишь новый вид логических операций.

Тем не менее, ситуация лучше, чем кажется. Оказывается, мы можем разработать алгоритмы обучения, которые смогут выполнить автоматическую настройку весовых коэффициентов и смещений в сети искусственных нейронов. Эта настройка происходит в ответ на внешние раздражители без прямого вмешательства программиста. Эти алгоритмы обучения позволяют использовать искусственные нейроны совершенно иначе, чем это происходит с логическими элементами. Вместо того, чтобы выстраивать схему из логических элементов, нейросети могут просто обучиться решению задач, причем решение некоторых из них было бы чрезвычайно затруднено при помощи традиционной схемы.

## Сигмоидальные нейроны

«Обучающиеся алгоритмы» – это звучит потрясающе. Но как мы можем разработать такие алгоритмы для нейронной сети? Предположим, что у нас есть сеть перцептронов, которую мы хотели бы использовать для решения некоторых задач. В качестве входных данных для сети можно было бы использовать необработанный массив пикселей, полученный со сканера изображений рукописных цифр. И мы хотим, чтобы сеть обучилась определять весовые коэффициенты и смещения таким образом, чтобы на выходе она могла правильно определять рукописные цифры. Чтобы увидеть, как работает обучение, предположим, что мы делаем небольшое изменение в каком-либо весовом коэффициенте (или смещении) в сети. И мы бы хотели для этого небольшого изменения получить соответствующее изменение на выходе из сети. Как мы увидим, именно это свойство нейронных сетей и делает возможным их обучение. Вот что мы хотим (понятно, что эта сеть слишком проста, чтобы распознавать рукописный текст!):

![image-center]({{ "/assets/images/chap1-2-1.png" | relative_url }}){: .align-center}

Если предположение о том, что небольшое изменение весового коэффициента (или смещения) вызывает такое же небольшое изменение на выходе, окажется верным, то мы могли бы использовать этот факт для изменения весовых коэффициентов и смещений так, чтобы научить нашу сеть вести себя так, как мы хотим. Например, предположим, что сеть ошибочно классифицировала изображение как «8», в том время как предъявлена была цифра «9». Мы могли бы выяснить, как сделать небольшое изменение в весовых коэффициентах и смещениях так, чтобы сеть немного приблизилась к классификации изображения как цифры «9». А затем мы будем снова и снова повторять эти изменения для получения лучшего результата распознавания. Таким образом сеть будет учиться.

Проблема заключается в том, что такой подход неприменим для сети, включающей в себя перцептроны. На самом деле, небольшое изменение веса или смещения любого отдельного перцептрона в сети иногда может полностью перевернуть выходные данные этого перцептрона: скажем, из $$0$$ в $$1$$. Такой переворот может изменить поведение остальной части сети. И даже если цифра «9» теперь определилась корректно, поведение сети по отношению ко всем другим изображениям, вероятно, изменилось. Становится трудно понять, как постепенное изменение весов и смещений модифицирует сеть, приближая ее к желаемому поведению. Может быть, существует какой-то хитрый способ обойти эту проблему. Но пока это не очевидно.

Мы можем решить эту проблему путем введения нового типа искусственного нейрона, называемого сигмоидальным нейроном. Сигмоидальные нейроны аналогичны перцептронам, однако изменены таким образом, что небольшое изменение в их весовых коэффициентах и смещении приводит к небольшому изменению на выходе. Это важное обстоятельство, которое позволит обучаться сети сигмоидальных нейронов.

Итак, позвольте мне описать сигмоидальный нейрон. Мы будем изображать его так же, как изображали перцептроны:

![image-center]({{ "/assets/images/chap1-2-2.png" | relative_url }}){: .align-center}

Сигмоидальный нейрон (так же, как перцептрон) имеет входы: $$x_1, x_2, ...$$. При этом входной сигнал может принимать любое значение в диапазоне от $$0$$ до $$1$$. Например, число $$0,638$$ - правильный вход для сигмоидального нейрона. Кроме того, у сигмоидального нейрона имеются также весовые коэффициенты для каждого входа: $$w_1, w2, ...$$, а также общий сдвиг (смещение) $$b$$. Однако выход не ограничивается только $$0$$ или $$1$$. Вместо этого используется выражение: $$\sigma (w \cdot x+b)$$, где $$\sigma$$ - сигмоидальная функция (кстати, $$\sigma$$ иногда называют логистической функцией, а соответствующий новый класс нейронов - логистическими нейронами. Эти термины используются многими людьми, работающими с нейронными сетями. Тем не менее, мы будем использовать в терминологии слово «сигмоида»), определяемая так:

$$\sigma(z)=\frac{1}{1+e^{-z}}$$

Выход сигмоидального нейрона с входами $$x_1,x_2,...$$, весами $$w_1,w_2,...$$. и смещением $$b$$:

$$\frac{1}{1+exp(-\sum_j w_j x_j - b))}$$

На первый взгляд кажется, что сигмоидальный нейрон очень отличается от перцептрона. Алгебраическая форма функции сигмоиды может показаться непонятной и отталкивающей, если вы не знакомы с ней. На деле у них есть много общего, и алгебраическая форма сигмоидальной функции оказывается скорее технической деталью, чем реальным препятствием.

Для того, чтобы понять сходство с моделью перцептрона, предположим, что выражение $$z\equiv w \cdot x+b$$ является большим положительным числом. Тогда $$e^{-z}\approx 0$$, и поэтому $$\sigma (z) \approx 1$$. Другими словами, когда значение $$z=w \cdot x+b$$ является большим и положительным, то выход сигмоидального нейрона примерно равен $$1$$, как и в случае с перцептроном. Теперь предположим, что выражение $$z=w \cdot x+b$$ намного меньше нуля. Тогда $$e^{-z}\rightarrow \infty$$, и $$\sigma (z) \approx 0$$. Поэтому, когда выражение $$z=w \cdot x+b$$ значительно меньше нуля, поведение сигмоидального нейрона близко к поведению перцептрона. Однако в том случае, когда $$w \cdot x+b$$ имеет малые значения, мы получаем значительные отклонения от модели перцептрона.

Что можно сказать об алгебраической форме функции $$\sigma$$? Как ее можно понять? На самом деле, точная форма $$\sigma$$ не слишком важна; что действительно важно, так это форма функции при построении графика. График имеет следующую форму:

![image-center]({{ "/assets/images/chap1-2-3.png" | relative_url }}){: .align-center}

Этот график представляет собой сглаженную версию пороговой функции

![image-center]({{ "/assets/images/chap1-2-4.png" | relative_url }}){: .align-center}

Если определять $$\sigma$$ как пороговую функцию, то из сигмоидального нейрона получится перцептрон, так как на выходе мы получим $$1$$ или $$0$$ в зависимости от того, будет ли функция $$w \cdot x+b$$ положительной или отрицательной. На самом деле, когда $$w \cdot x+b=0$$, выход перцептрона равен $$0$$, при этом значение функции равно $$1$$. Так что, строго говоря, мы должны были бы изменить пороговую функцию в одной этой точке. Используя фактические значения функции $$\sigma$$, мы, как уже было показано ранее, получаем сглаженную модель перцептрона. На самом деле, значимым фактором является именно эта сглаженность, а не ее детальная форма. Плавность перехода значений функции $$\sigma$$ означает, что небольшие изменения $$\Delta wj$$ в весах и $$\Delta b$$ в смещениях будут приводить к небольшому изменению $$\Delta output$$ (выхода) на выходе этого нейрона. На самом деле, вычисления дают нам понять, что $$\Delta output$$ хорошо аппроксимируется:

$$\Delta output \approx \sum_j\frac{\delta output}{\delta w_j}\Delta w_j+\frac{\delta output}{\delta b}\Delta b$$

где сумма берется по всем весам $$w_j$$, а $$\frac{\delta output}{\delta w_j}$$ и $$\frac{\delta output}{\delta b}$$ обозначают частные производные от выхода относительно $$w_j$$ и $$b$$ соответственно. Не паникуйте, если вы не знакомы с частными производными! И, хотя приведенное выше выражение со всеми частными производными выглядит сложным, оно всего лишь то, что $$\delta output$$ является *линейной функцией* изменений $$\Delta w_j$$ и $$\Delta b$$ в весовых коэффициентах и смещениях. Ее линейность позволяет легко совершать небольшие изменения в весах и смещениях для достижения любого желаемого (небольшого) изменения на выходе. Таким образом, сигмоидальные нейроны (так же, как и перцептроны) дают ясное понимание того, как изменение весовых коэффициентов и смещений меняет выходные значения.

Если важен только образ функции $$\sigma$$, а не ее строгая форма, то почему мы используем именно конкретную формулу для $$\sigma$$, взятую из выражения $$(3)$$? На самом деле, позднее в этой книге мы будем иногда рассматривать нейроны, где выход, равный $$f(w \cdot x+b)$$ использует какую-либо другую *функцию активации* $$f(\cdot)$$. Главное то, что при использовании различных функций активации изменяться будут лишь значения частных производных из выражения $$(5)$$. Оказывается, что, когда мы будем вычислять эти частные производные, использование функции $$\sigma$$ значительно упростит алгебру, поскольку ее производную можно будет выразить через саму функцию. В любом случае, функция $$\sigma$$ часто используется в работах, посвященных нейронным сетям, и ею мы будем пользоваться чаще всего.

Как мы можем интерпретировать выход сигмоидального нейрона? Очевидно, что разница между перцептроном и сигмоидальным нейроном заключается в том, что выход последнего может иметь любое значение в диапазоне между $$0$$ и $$1$$, так что даже значения вроде $$0,173$$ или $$0,689$$ вполне допустимы. Это свойство может быть полезным, например, в том случае, если мы хотим использовать выходное значение для представления средней интенсивности пикселов во входном изображении нейросети. Но иногда то же самое может быть помехой. Предположим, что мы хотим, чтобы выход в сети указывал: «входное изображение – это цифра 9» или «входное изображение – это не цифра 9». Очевидно, что проще всего было осуществить это, если бы выход был равен $$0$$ или $$1$$ (как в перцептроне). Хотя на практике мы можем, например, решить, что выход, значение которого более $$0,5$$, является индикацией того, что выполняется событие «это цифра 9», а выход, значение которого меньше 0,5, сообщает нам, что «эта цифра не равна 9». Я всегда буду комментировать подобные обозначения, чтобы у нас не возникало недопонимания.

### Упражнения

Сигмоидальные нейроны, имитирующие перцептрон. Часть 1.

Предположим, что мы возьмем все весовые коэффициенты и смещения в сети перцептронов и умножим их на положительную константу $$c$$, где $$c>0$$. Докажите, что поведение сети не изменится.

Сигмоидальные нейроны, имитирующие перцептрон. Часть 2.

Возьмем условия из предыдущей задачи: у нас имеется сеть перцептронов. Предположим, что вход в сети перцептронов был задан. Нам не нужно его фактическое значение; важно лишь, чтобы он был фиксирован. Предположим, что весовые коэффициенты и смещения заданы так, что $$w \cdot x+b \neq 0$$ для заданного входа $$x$$, и это применимо для каждого перцептрона в сети. Теперь замените все перцептроны в сети на сигмоидальные нейроны и умножьте значения весов и смещений на положительную константу $$c$$, где $$c>0$$. Покажите, что в пределе при $$\lim_{ } c\rightarrow \infty$$ поведение этой сети сигмоидальных нейронов является точно таким же, как и для сети перцептронов. Какие ошибки могут произойти в случае, если для одного из перцептронов $$w \cdot x+b=0$$?

## Архитектура нейронных сетей

В этом разделе мы познакомимся с нейронной сетью, которая может хорошо классифицировать рукописные цифры. В ходе подготовки мы попробуем разобраться с некоторой терминологией, с помощью которой мы определим различные части сети. Допустим, у нас есть сеть:

![image-center]({{ "/assets/images/chap1-3-1.png" | relative_url }}){: .align-center}

Как уже говорилось ранее, крайний левый слой в этой сети называется входным слоем, а нейроны в пределах слоя называются входными нейронами. Крайний правый (или выходной) слой содержит выходные нейроны (в нашем случае один). Средний слой называют скрытым слоем, так как нейроны в этом слое не являются ни входами, ни выходами. Возможно, термин «скрытый» звучит немного загадочно. Когда я впервые услышал его, я подумал, что он должен иметь какое-то глубокое философское или математическое значение. Но на самом деле он означает лишь то, что слой не является ни входом, ни выходом. Сеть выше имеет только один скрытый слой; при этом у некоторых сетей бывает несколько скрытых слоев. Например, следующая сеть имеет четыре слоя, из которых два - скрытые:

![image-center]({{ "/assets/images/chap1-3-2.png" | relative_url }}){: .align-center}

Хотя это может быть сбивать с толку, но так сложилось исторически, что такие сети с множеством слоев иногда называют многослойным перцептроном или MLP (multilayer perceptron) даже несмотря на то, что они состоят из сигмоидальных нейронов, а не перцептронов. Я не собираюсь использовать в книге термин MLP, но хочу предупредить вас о его существовании.

Конструкция входных и выходных слоев в сети часто бывает довольной простой. Например, предположим, что мы пытаемся определить, является ли рукописное изображение цифрой «9» или же нет. Обычно, при проектировании сети используется кодирование яркостей пикселей изображения в входных нейронах. Если размер изображения равен $$64$$ на $$64$$ в черно-белом формате, то мы имеем $$4096=64\times 64 $$ входных нейронов с яркостью, которая масштабирована соответствующим образом в диапазоне от $$0$$ до $$1$$. Выходной слой будет содержать только один нейрон, где выходное значение менее $$0,5$$ будет означать, что «входное изображение не является цифрой 9», а значение более $$0,5$$ – «входное изображение является цифрой 9».

В то время как конструкция входных и выходных слоев нейронной сети часто задана простым образом, конструкция скрытых слоев может быть довольно искусной. В частности, не представляется возможным подвести итоги процесса проектирования для скрытых слоев при помощи нескольких простых правил. Вместо этого, исследователи нейронных сетей разработали множество конструкций эвристик для скрытых слоев, которые помогают получить информацию о поведении нейронных сетей. Например, такие эвристики могут быть использованы, чтобы помочь определить степень компромисса между количеством скрытых слоев и временем, необходимым для обучения сети. Далее в этой книге мы встретим несколько таких конструкций эвристик.

До сих пор мы рассматривали нейронные сети, где выход из одного слоя используется в качестве входных данных к следующему слою. Такие сети называются нейронными сетями прямого распространения. Это означает, что в сети нет циклов – информация всегда подается вперед и никогда не поступает обратно. Если у нас имеются циклы, мы бы в конечном счете сталкивались с ситуациями, когда вход в функцию $$\sigma$$ зависит от ее выхода. Такая конструкция трудна для объяснения, поэтому мы не используем их в книге.

Тем не менее, существуют и другие модели искусственных нейронных сетей, в которых возможна структура обратной связи. Такие модели называются рекуррентными нейронными сетями. Идея, заложенная в этих моделях, в том, что нейроны активируются в течение некоторого ограниченного периода времени, прежде чем перейти в состояние покоя. Такая активация может стимулировать другие нейроны, которые могут активироваться через некоторое время и в течение ограниченного периода времени. Таким образом, активируется еще больше нейронов, и поэтому с течением времени мы получаем каскад активаций нейронов. Циклы не вызывают проблем в такой модели, так как на выход нейрона влияет его вход только через некоторое время, а не мгновенно.

Рекуррентные нейронные сети распространены несколько реже, чем нейронные сети прямого распространения, отчасти потому, что алгоритмы обучения для рекуррентных сетей менее мощны (по крайней мере на сегодняшний день). Но рекуррентные сети, несмотря на это, по-прежнему чрезвычайно интересны. Они гораздо ближе по духу к реальной работе мозга чем сети прямого распространения. И вполне возможно, что рекуррентные сети смогут решать важные задачи, которые, при использовании сетей прямого распространения, могут быть решены с большими трудностями. Тем не менее, чтобы ограничить сферу нашей деятельности, в этой книге мы будем концентрироваться на более широко используемых сетях прямого распространения.

## Простая сеть для классификации рукописных цифр

Познакомившись с нейронными сетями, давайте вернемся к задаче распознавания рукописного ввода. Мы можем разбить задачу распознавания рукописных цифр на две подзадачи. Во-первых, мы хотели бы знать способ разбиения изображения, содержащего несколько цифр в последовательность отдельных изображений, каждое из которых содержит одну цифру. Например, мы хотели бы разбить изображение

![image-center]({{ "/assets/images/chap1-4-1.png" | relative_url }}){: .align-center}

на шесть разных картинок:

![image-center]({{ "/assets/images/chap1-4-2.png" | relative_url }}){: .align-center}

Для человека задача покажется очень легкой, но задача правильного разбиения изображения будет сложной для компьютерной программы. После разбиения изображения на сегменты, программа должна классифицировать каждую отдельную цифру. Так, например, мы хотели бы, чтобы программа распознала первую цифру на изображении выше,

![image-center]({{ "/assets/images/chap1-4-3.png" | relative_url }}){: .align-center}

как цифру «5».

Мы сконцентрируемся на написании программы для решения второй задачи, то есть для классификации отдельных цифр. Мы займемся ей, так как проблему сегментации не так трудно решить, если у вас имеется хороший способ классификации отдельных цифр. Имеется несколько подходов к решению задачи сегментации. Один способ заключается в создании множества разных попыток сегментации изображения, используя отдельные классификаторы цифр для оценки каждой сегментации. Попытка сегментации получает высокую оценку, если каждый классификатор цифры уверен в своей классификации во всех сегментах, а также низкий балл, если классификатор, имеет плохое качество в одном или нескольких сегментах. Идея заключается в том, что если у классификатора возникают проблемы, то, вероятно, их причиной является неверный выбор сегментации. Этот и другие способы могут быть использованы для решения задачи сегментации достаточно хорошо. Таким образом, вместо того, чтобы беспокоиться о сегментации мы будем концентрироваться на разработке нейронной сети, которая может решить более интересную и сложную задачу, а именно, задачу распознавания отдельных рукописных цифр.

Для распознавания отдельных цифр мы будем использовать трехслойную нейронную сеть:

![image-center]({{ "/assets/images/chap1-4-4.png" | relative_url }}){: .align-center}

Входной слой сети содержит нейроны, кодирующие значения пикселей на входе. Как уже обсуждалось выше, наша обучающая выборка данных для сети будет состоять из отсканированных изображений рукописных цифр размерностью $$28$$ на $$28$$ пикселей. Таким образом входной слой содержит $$784=28\times 28$$ нейронов. На изображении выше большая часть из $$784$$ входных нейронов была опущена. Входные пиксели заданы в оттенках серого, со значением $$0,0$$ для преставления белого, значение $$1,0$$ представляет черный цвет, а в промежутке между этими значениями представлены оттенки серого от светлого к темному.

Второй слой сети представляет собой скрытый слой. Обозначим число нейронов в этом скрытом слое за $$n$$, мы будем экспериментировать с различными значениями $$n$$. Пример выше, иллюстрирует небольшой скрытый слой, содержащий только $$n=15$$ нейронов.

Выходной слой сети содержит $$10$$ нейронов. Если первый нейрон активирован, то есть его выход $$\approx 1$$, то это означает, что сеть считает данную цифру как $$0$$. Если активируется второй нейрон, то это означает, что сеть считает представленную цифру как $$1$$. И так далее. Говоря более точно, мы пронумеровываем выходные нейроны от $$0$$ до $$9$$, и находим нейрон с наибольшим значением активации. Если этот нейрон, например, соответствует цифре $$6$$, то это будет означать, что сеть считает цифру, показанную ей на входе, цифрой 6. И так далее по аналогии для других нейронов.

Вы можете спросить, почему мы используем $$10$$ выходных нейронов? В конце концов, сеть нужна нам для того, чтобы сообщить нам, какая цифра  $$(0,1,2,...,9)$$ соответствует входному изображению. Казалось бы, простейший способ сделать это, заключается в использовании только $$4$$ выходных нейронов, рассматривая каждый нейрон как двоичное значение, показывающее близость ответа к $$0$$ или к $$1$$. Четырех нейронов выходного слоя достаточно для кодирования ответа, так как $$2^4 = 16$$, что больше, чем $$10$$ возможных значений для цифр. Почему наша сеть должна использовать $$10$$ нейронов вместо этого? Разве это неэффективно? Однако, опытным путем можно выяснить: мы можем попробовать оба варианта сетей, и оказывается, что для этой конкретной проблемы, сеть с $$10$$ выходными нейронами учится распознавать цифры лучше, чем сети с $$4$$-мя выходными нейронами. Но это не объясняет нам, почему использование $$10$$ выходных нейронов работает лучше. Имеется ли в основании такого решения какая-нибудь теория, которая скажет нам заранее, что мы должны использовать $$10$$-выходную кодировку вместо $$4$$-выходной кодировки?

Для того чтобы разобраться в этом, нужно понять основные принципы обучения нейронной сети. Сперва рассмотрим случай, когда мы используем $$10$$ выходных нейронов. Давайте сконцентрируемся на первом выходном нейроне, который пытается решить задачу: является ли изображение цифрой «0»? Он делает это путем взвешивания признаков из скрытого слоя нейронов. Какую работу выполняют эти скрытые нейроны? Предположим, в рамках доказательства, что первый нейрон в скрытом слое определяет, имеется ли в изображении данный фрагмент:

![image-center]({{ "/assets/images/chap1-4-5.png" | relative_url }}){: .align-center}

Нейрон присваивает большие веса входным пикселям похожим на этот фрагмент, и меньшие веса в случае других входных данных. Аналогичных образом, в рамках доказательства, будем считать, что второй, третий и четвертый нейроны в скрытом слое должны обнаруживать присутствие следующих фрагментов:

![image-center]({{ "/assets/images/chap1-4-6.png" | relative_url }}){: .align-center}

Как вы уже догадались, эти четыре изображения вместе составляют изображение цифры «0», которую мы видели ранее в книге.

![image-center]({{ "/assets/images/chap1-4-7.png" | relative_url }}){: .align-center}

Так, при активации всех этих четырех нейронов скрытого слоя, можно сделать вывод, что представленное изображение является цифрой «0». Конечно, это не единственный способ доказательства, который мы можем использовать, для того чтобы определить является ли показанное изображение цифрой «0». Существует множество других способов, например, через преобразование или искажение над картинками. Но наши выводы о том, как можно распознать цифру «0», в нашем примере не являются сомнительными.

Таким образом, мы можем дать правдоподобное объяснение того, почему лучше иметь $$10$$ выходов из сети, а не $$4$$. Если бы мы имели $$4$$ выхода, то первый выходной нейрон пытался бы оценивать значимость бита принадлежности цифры. И нет никакого очевидного способа связать значимость бита с простыми фрагментами цифры, как показано выше. Трудно себе представить, что имеется какая-то хорошая связь между фрагментами изображения цифры и значимостью бита на выходе.

Все вышесказанное получено опытным путем. Нельзя сказать, что трехслойная нейронная сеть работает именно так, как я описал, со скрытыми нейронами, которые распознают простые фрагменты изображения. Может быть искусный алгоритм обучения сможет найти такие значения весовых коэффициентов, которые позволят нам использовать только 4 выходных нейрона. Но эвристика, как образ мышления, работает довольно хорошо, и поможет вам сэкономить много времени при разработке хороших архитектур нейронных сетей. 

### Упражнения

Существует способ определения побитового представления цифр, добавив дополнительный слой к вышеупомянутой трехслойной сети. Дополнительный слой преобразует выходной сигнал предыдущего слоя в двоичном представлении, как показано на рисунке ниже. Необходимо найти набор весовых коэффициентов и смещений для нового выходного слоя. Предположим, что первые $$3$$ слоя нейронов такие, что правильный выход в третьем слое (т.е. старый выходной слой) имеет активацию по меньшей мере в $$0,99$$, и некорректные выходы имеют активации меньше, чем $$0,01$$.

![image-center]({{ "/assets/images/chap1-4-8.png" | relative_url }}){: .align-center}

## Обучение с использованием градиентного спуска

Теперь, когда у нас есть дизайн для нашей нейронной сети, то как она может обучиться распознавать цифры? Первое, что нам нужно, это набор данных, для обучения сети – так называемая обучающая выборка. Мы будем использовать набор данных MNIST , который содержит десятки тысяч отсканированных изображений рукописных цифр вместе с их правильной классификацией. Название MNIST исходит из того, что набор представляет собой модифицированное подмножество из двух наборов данных, собранных NIST, национальным институтом стандартов и технологий США. Вот несколько изображений из MNIST:

![image-center]({{ "/assets/images/chap1-5-1.png" | relative_url }}){: .align-center}

Как вы можете видеть, эти цифры, аналогичны по сути показанным в начале этой главы. Конечно, при тестировании нашей сети мы будем распознавать изображения, которые не находятся в обучающей выборке.

Данные набора MNIST состоят из двух частей. Первая часть содержит $$60000$$ изображений, которые будут использоваться в качестве обучающей выборки. Это сканированные изображения почерка $$250$$ человек, половина из которых была сотрудниками бюро переписи США, другая половина из них была старшеклассниками. Изображения хранятся в градациях серого размером $$28$$ на $$28$$ пикселей. Вторая часть набора данных MNIST состоит из $$10000$$ изображений, которые будут использоваться в качестве тестовых данных, формат и размер которых аналогичен обучающей выборке. Мы будем использовать тестовые данные для оценки качества распознавания цифр нашей нейронной сетью. Для пущей эффективности оценки результат, тестовые данные были взяты из другой группы размером в $$250$$ человек, которая также состоит из сотрудников бюро переписи населения и старшеклассников. Это даст нам уверенность в том, что наша система может распознать цифры, введенные теми людьми, на почерке которых сеть не обучалась.

Мы будем использовать обозначение $$x$$ для входных данных. Нам будет удобно рассматривать каждый вход обучения $$x$$ как $$28\times 28=784$$-мерный вектор. Каждая запись в векторе представляет собой значение уровня серого для одного пикселя в изображении. Мы будем обозначать соответствующие выходные данные $$y=y(x)$$, где $$y$$ представляет собой $$10$$-мерный вектор. Например, если данное изображение $$x$$, представляет собой цифру «6», то на выходе сети имеем: $$y(x)=(0,0,0,0,0,0,1,0,0,0)^T$$. Обратите внимание, что обозначение $$T$$ здесь является операцией транспонирования, которая превращает вектор-строку в обычный вектор-столбец.

Мы бы хотели получить алгоритм, который позволяет нам найти веса и смещения так, чтобы выход сети был приблизительно равен $$y(x)$$ для всей обучающей выборки $$x$$ на входе. Для того, чтобы количественно оценить, насколько хорошо мы близки к этой цели, мы определяем функцию потерь:

$$C(w,b)\equiv \frac{1}{2n}\sum_{x}\left \| y(x)-a \right \|^2$$

Здесь $$w$$ обозначает совокупность всех весов в сети, $$b$$ всех смещений, $$n$$ – размер обучающей выборки, $$a$$ – это вектор выходов из сети при входе $$x$$, сумма берется над всей обучающей выборкой $$x$$. Конечно, выход $$a$$ зависит от $$x$$, $$w$$, $$b$$, но для простоты обозначения эта зависимость не указана. Обозначение $$\left \| v \right \|$$ является обычной функцией длины для вектора $$v$$. Мы будем называть $$C$$ *квадратичной* функцией потерь, ее также иногда называют *среднеквадратичной ошибкой* или *MSE (mean squared error)*. Очевидно, что $$C(w,b)\geq 0$$, так как каждый член суммы не является отрицательным. Кроме того, значение $$C(w,b)$$ становится малым, то есть $$C(w,b)\approx 0$$ именно тогда, когда $$y(x)$$ приблизительно равен выходу $$a$$ для всей обучающей выборки $$x$$. Таким образом, наш алгоритм обучения хорошо справился с своей работой, если он может найти веса и смещения так, что $$C(w,b)\approx 0$$. В противоположность этому, результат работы алгоритма не так хорош, когда значение $$C(w,b)$$ велико – это будет означать что значение $$y(x)$$ не близко к $$a$$ для большего числа входов. Таким образом, целью нашего алгоритма обучения является минимизация функции потерь $$C(w,b)$$ в зависимости от весов и смещений, которые уменьшают значение функции потерь. Мы сделаем это с помощью алгоритма, называемого градиентным спуском.

Зачем возводить функцию в квадрат? Ведь мы разве не заинтересованы в первую очередь в увеличении количества изображений, классифицированных правильно сетью? Почему бы не попытаться увеличить их количество напрямую, а не сводя это к минимизации зависимой функции, такой как квадратичная функция? Проблема заключается в том, что количество правильно классифицированных изображений не будет являться гладкой функцией весов и смещений в сети. По большому счету, делая небольшие изменений в весах и смещениях, вряд ли вообще возможно хоть как-то изменить количество изображений, классифицированных правильно. Поэтому трудно понять, как изменять параметры сети, чтобы увеличить точность классификации. Однако, если мы вместо этого будем использовать гладкую функцию, например, квадратичную функцию потерь, то оказывается легко представить, как производя небольшие изменения в весах и смещениях, улучшать результат, получаемый сетью. Именно поэтому мы ориентируемся в первую очередь на сведение к минимуму квадратичной функции, и только после этого мы будем исследовать точность классификации.

Даже если учесть, что мы хотим использовать гладкую функцию потерь, вы можете задаться вопросом: «Почему мы выбираем квадрат функции в уравнении $$(6)$$? Чем обусловлен такой выбор? Возможно, выбрав другую функцию потерь, мы бы получили совершенно другой результат минимизации функции с другими весами?» Это действительно хороший вопрос, и мы вернемся к выбору функции потерь и некоторым ее модификациям несколько позднее. Тем не менее, квадратичная функция потерь из уравнения $$(6)$$ работает отлично для понимания основ обучения нейронных сетей, поэтому мы будем использовать далее.

Резюмируя, в обучении нейронной сети нашей целью является нахождение таких весов и смещений, которые минимизируют квадратичную функцию потерь $$C(w,b)$$. Задача поставлена явно, но у нее есть множество дополнительных нюансов таких как: интерпретация $$w$$ и $$b$$ в качестве коэффициентов весов и смещений, скрытая функция $$\sigma$$, выбор архитектуры сети, набор данных MNIST и прочее. Однако сейчас для понимания работы сети, достаточно игнорировать большую часть этого, просто сосредоточившись на аспекте минимизации. Так что сейчас мы можем забыть о специфической форме функции потерь, о связях в нейронной сети и так далее. Вместо этого мы будем считать, что имеем функцию многих переменных, и хотим ее минимизировать. Мы собираемся разработать методику, которая называется *методом градиентного спуска*, который может быть использован для решения таких задач минимизации. Затем уже мы вернемся к конкретной функции, которую мы хотим свести к минимуму для обучения нейронной сети.

Хорошо, давайте предположим, что мы пытаемся минимизировать некоторую функцию $$C(v)$$. Это может быть любая действительная функция многих переменных,  $$v=v_1,v_2,...$$. Обратите внимание, что я заменил обозначения $$w$$ и $$b$$ на $$v$$, чтобы подчеркнуть, что функция может быть любой – сейчас мы рассуждаем вне контекста нейронных сетей. Для упрощения будем считать функцию $$C$$ как функцию только двух переменных, которые мы будем обозначать как $$v_1$$ и $$v_2$$.

![image-center]({{ "/assets/images/chap1-5-2.png" | relative_url }}){: .align-center}

Нас интересует нахождение глобального минимума функции $$C$$. Для функции, график которой расположен выше, поиск точки глобального минимума тривиален, ее можно найти, просто посмотрев на график. В нашем примере, возможно, приведена слишком простая функция. Однако в общем виде, функция $$C$$ может быть очень сложной функцией многих переменных, и нахождение ее минимума может быть не так очевидно.

Одним из способов решения этой задачи является нахождение минимума аналитически. Мы могли бы вычислить производные, а затем попытаться использовать их, чтобы найти точки экстремума функции $$C$$. В удачном случае это может сработать, когда функция $$C$$ является функцией одной или нескольких переменных. Но в нейронных сетях часто используется гораздо больше переменных – крупнейшие нейронные сети имеют функции потерь, которые зависят от миллиарда весов и смещений, запутанных чрезвычайно сложным образом. Аналитический подход просто не будет работать!

После утверждения, что достаточно представить функцию $$C$$, как функцию только двух переменных, я дважды упомянул, что функция может быть более чем от двух переменных. Однако, для наших целей, такое представление функции $$C$$, как функции от двух переменных, может действительно помочь в восприятии задачи. Такой подход применим, когда картина на самом деле выглядит намного сложнее, как было упомянуто ранее. Математику можно представить, как множество интуитивных образов, используя совокупность образов или же используя их по одному для лучшего восприятия.

Итак, аналитический способ не применим. К счастью, есть прекрасная аналогия, которая предлагает алгоритм, который работает довольно хорошо. Давайте представим нашу функцию как о своего рода желобе. Это довольно просто представить, посмотрев на график выше. Представим себе шар, который скатывается по склону желоба. Наш повседневный опыт подсказывает нам, что шар будет в конечном счете катиться к нижней части желоба. Можем ли мы использовать такую аналогию как способ нахождения минимума функции? Мы бы могли случайным образом выбрать отправную точку для (воображаемого) шара, а затем имитируя движение шара, рассчитать траекторию движения вниз к нижней точке желоба. Мы могли бы сделать такое моделирование просто путем вычисления производных (в некоторых случаях вторых производных) функции $$C$$ – эти производные рассказали бы о локальной области желоба, и, следовательно, траекторию движения шара.

Исходя из вышесказанного, вы могли бы предположить, что мы пытаемся записать уравнения движения Ньютона для шара, основываясь на явлениях силы трения, тяжести и так далее. В действительности мы не собираемся использовать полную аналогию катящегося шара, мы только пытаемся вывести алгоритм для минимизации функции $$C$$, а не точную физическую модель. Аналогия с движением шара призвана стимулировать наше воображение не ограничивая наше мышление. Поэтому вместо того, чтобы погружаться в детали физики, давайте просто представим, что мы могли бы управлять законами физики, диктуя шару, куда он должен двигаться. Какими законами движения мы бы могли воспользоваться, чтобы шар всегда катился к нижней точке желоба?

Для придания вопросу большей точности, давайте думать о том, что происходит, когда мы придаем небольшое движение шару $$\Delta v_1$$ в направлении $$v_1$$, и небольшое движение $$\Delta v_2$$ в направлении $$v_2$$. Математика говорит нам, что функция $$C$$ изменится следующим образом:

$$\Delta C \approx\frac{\delta C}{\delta v_1}\Delta v_1 + \frac{\delta C}{\delta v_2}\Delta v_2$$

Мы собираемся найти способ выбора $$\Delta v_1$$ и $$\Delta v_2$$ таким образом, чтобы сделать отрицательным значение $$\Delta C$$, то есть мы выберем их так, чтобы шар катился вниз по желобу. Для того, чтобы выяснить, как их можно подобрать, нам поможет $$\Delta v$$, который определяется как вектор изменений в $$v$$, $$\Delta v \equiv (v_1,v_2)^T$$, где $$T$$ – операция транспонирования, которая превращает векторы-строки в векторы-столбцы. Также определим градиент $$C$$, который является вектором частных производных, $$(\frac {\delta C}{\delta v_1},\frac {\delta C}{\delta v_2})^T$$. Обозначив градиент $$\nabla С$$, получаем:

$$\nabla C=(\frac {\delta C}{\delta v_1},\frac {\delta C}{\delta v_2})^T$$

Теперь мы можем выразить $$\Delta C$$ в терминах $$\Delta v$$ и градиента $$\nabla С$$. Но перед этим я хочу разъяснить понятие градиента, поскольку многие люди испытывают затруднения в его понимании. При встрече обозначения $$\nabla С$$ в первый раз, люди часто спрашивают: «Что, собственно, означает символ $$\nabla С$$?» На самом деле, можно считать запись $$\nabla С$$ единым математическим объектом – вектором, который может быть записан с использованием двух символов. С этой точки зрения, символ $$\nabla$$ является просто частью нотации, которая указывает вам, что запись $$\nabla С$$ будет записью градиента вектора. Есть более корректные точки зрения, где $$\nabla$$ можно рассматривать в качестве независимого математического объекта, например, в качестве дифференциального оператора, но мы не будем рассматривать такие точки зрения.

С помощью этих определений, выражение (7) для $$\Delta C$$ можно переписать в виде:

$$\Delta C \approx \nabla C \cdot \Delta v$$

Это уравнение объясняет почему $$\nabla C$$ называется градиентом вектора: значение $$\nabla C$$ связано с отношением приращений в $$v$$ и $$C$$, что мы и ожидаем от градиента по определению. Но действительно, что интересно в уравнении – это то, что мы можем видеть, как выбрать $$\Delta v$$ таким, чтобы получить отрицательные значения $$\Delta C$$. В частности, предположим, что мы выбираем:

$$\Delta v=-\eta \nabla C$$

где $$\eta$$ – это небольшой, положительный параметр (называемый *скоростью обучения*). Тогда уравнение (9) говорит нам, что $$\Delta C \approx -\eta \nabla C \cdot \nabla C = -\eta {\left \| \nabla C \right \|}^2$$. Поскольку $${\left \| \nabla C \right \|}^2 \geq 0$$, это означает, что $$\Delta C \leq 0$$, то есть $$С$$ будет всегда уменьшаться, а не увеличиваться при изменении $$v$$ в соответствии с уравнением (10) (в пределах приближения в уравнении (9)).
Это именно то свойство, которое мы искали! Поэтому возьмем уравнение (10) в качестве определения «закона движения» для шара в алгоритме градиентного спуска. То есть, мы будем использовать уравнение (10) для вычисления значения $$\Delta v$$, затем перемещать положение шара в данное значение:

$$v\rightarrow {v}'=v-\eta \nabla C$$

Тогда мы будем использовать это правило обновления шага градиентного спуска еще раз, чтобы сделать еще один шаг. Если мы будем продолжать делать это снова и снова, мы добьемся уменьшения $$C$$ до тех пор, пока мы достигнем глобального минимума.

Подводя итог, алгоритм градиентного спуска работает путем пошагового вычисления градиента $$\nabla C$$, двигаzcь в противоположном направлении, словно «падая» по склону желоба. Мы можем представить себе это так:

![image-center]({{ "/assets/images/chap1-5-3.png" | relative_url }}){: .align-center}

Обратите внимание на то, что это правило градиентного спуска не соотносится с реальным физическим движением. В реальной жизни шар имеет импульс, и при помощи импульса шар может катиться по желобу дальше вниз или кратковременно вверх. И только после того, как сила трения, действующая на шар остановит его, он скатится вниз по желобу. В противоположность этому, наше правило просто говорит: «идти вниз, прямо сейчас». Хорошее правило для нахождения минимума!

Для правильной работы градиентного спуска необходимо выбрать скорость обучения $$\eta$$, его значение должно быть достаточно малым для того, чтобы уравнение (9) являлось хорошим приближением. Если мы этого не сделаем, то можем получить в итоге $$\Delta C>0$$, такой результат нам не нужен! В то же время, мы не хотим, чтобы значение $$\eta$$ было слишком маленьким, так как это будет вносить небольшие изменения в $$\Delta v$$, и, таким образом, алгоритм градиентного спуска будет работать очень медленно. На практике $$\eta$$ часто изменяется, так что уравнение (9) остается хорошим приближением, но алгоритм работает не слишком медленно. Позже мы увидим, как это работает.

Я объяснил метод градиентного спуска для случая, когда $$C$$ является функцией двух переменых. Но, на самом деле, все работает так же хорошо, когда $$C$$ является функцией более многих переменных. Предположим, в частности, что $$C$$ является функцией от $$m$$ переменных, то есть $$v_1,...v_m$$. Тогда приращение $$\Delta$$ в $$C$$ производится небольшим изменением $$\Delta v = (\Delta v_1,...,\Delta v_m)^T$$. Получаем:

$$\Delta C \approx \nabla C \cdot \Delta v$$

где градиент $$\nabla C$$ является вектором

$$\nabla C \equiv \left ( \frac{\delta C}{\delta v_1},..., \frac{\delta C}{\delta v_m}\right )^T$$

Так же, как для случая двух переменных, мы можем выбрать:

$$\Delta v = - \eta \nabla C$$

и мы можем быть уверены, что наше (приблизительное) выражение (12) для $$\Delta C$$ будет отрицательным. Мы получаем способ нахождения минимума градиента даже для случая, когда $$C$$ является функцией многих переменных, путем многократного применения правила градиентного шага.

$$v\rightarrow {v}'=v-\eta\nabla C$$

Вы можете считать, что это правило обновления шага является определением алгоритма градиентного спуска. Таким образом, минимум функции $$C$$ находится путем многократного изменения положения $$v$$. Способ работает не всегда – существует несколько исключений, когда метод градиентного спуска не может найти глобальный минимум функции $$C$$. К этим ситуациям мы вернемся в последующих главах. Но на практике метод градиентного спуска чаще работает хорошо, и для нейронных сетей этот метод является отличным способом минимизации функции потерь, что помогает сети учиться.

На самом деле, имеется доля здравого смысла в том, что градиентный спуск является оптимальной стратегией для поиска минимума. Давайте предположим, что мы пытаемся сделать шаг $$\Delta v$$ в сторону максимального уменьшения функции $$C$$. Это эквивалентно минимизации $$\Delta C \approx \nabla C \cdot \Delta v$$. Мы будем ограничивать размер шага: $$\left \| \Delta v \right \| = \epsilon$$, где $$\epsilon >0$$ – небольшое фиксированное значение. Другими словами, мы хотим совершить небольшой шаг фиксированного размера для нахождения направления движения, которое уменьшит значение $$C$$ как можно больше. Можно доказать, что выбор $$\Delta v$$, которое минимизирует значение $$\nabla C \cdot \Delta v$$ является $$\Delta v =-\eta \nabla C$$, где $$\eta=\epsilon/\left \| \nabla C \right \|$$ определяется размером ограничения $$\left \| \Delta v \right \| = \epsilon$$. Таким образом, метод градиентного спуска можно рассматривать как метод совершения малых шагов в направлении максимального убывания $$C$$.

### Упражнения

Докажите утверждение последнего абцаза. Подсказка: стоит ознакомиться с неравенством Коши-Шварца.

При объяснении метода градиентного спуска рассматривалась ситуация для случая когда $$C$$ являлась функцией двух и более переменных. Какой будет $$C$$ для случая функции одной переменной? Приведите пример геометрической интерпретации для метода градиентного спуска с одной переменной.

Исследователи изучали множество вариаций градиентого спуска, в том числе те, которые моделируют движения реального шара. Такие методы имеют некоторые преимущества, но также имеют существенный недостаток: необходимо вычислить вторые частные производные, и такая операция может быть довольно трудозатратной. Для оценки количества вычислений предположим, что мы хотим вычислить все вторые частные производные $$\delta^2 C /\delta v_j \delta v_K$$. Если имеется миллион переменных $$v_j$$, то для вычисления вторых частных производных потребовалось бы около триллиона (миллион в квадрате) операций. Такая операция будет вычислительно дорогостоящей. С учетом сказанного, имеются приемы для предотвращения такого рода проблем, также активной областью исследования является нахождение альтернатив методу градиентного спуска. Но в этой книге мы будем использовать градиентный спуск (и его вариации) в качестве основного подхода к обучению нейронных сетей.

Как мы можем применить градиентный спуск к обучению в нейронной сети? Идея заключается в том, чтобы использовать  градиентный спуск для нахождения весовых коэффициентов $$w_k$$ и смещений $$b_l$$, которые минимизируют значение функции в уравнении (6). Чтобы понять, как это работает, давайте пересчитаем правило обновления градиентного спуска с весами и смещениями путем замены переменной $$v_j$$. Другими словами, наша «позиция» теперь состоит из компонентов $$w_k$$ и $$b_l$$, а вектор градиента $$\nabla C$$ имеет соответствующие компоненты $$\delta C/\delta w_k$$ и $$\delta C/\delta b_l$$. Переписав правило обновления градиентного спуска, получаем:
$$w_k\rightarrow {w}'_k = w_k - \eta \frac{\delta C}{\delta w_k}$$

$$w_k\rightarrow {w}'_k = w_k - \eta \frac{\delta C}{\delta w_k}$$

При повторном применении этого правила обновления мы можем «свернуть вниз по склону» и надеемся найти минимум функции потерь. Другими словами, это правило может быть использовано для обучения нейронной сети.

Имеется целый ряд проблем в области применения правила обновления градиентного спуска. Мы рассмотрим их подробнее в следующих главах. Но сейчас я просто хочу упомянуть об одной проблеме. Для понимания проблемы, давай вернемся к уравнению (6). Заметьте, что функция потерь имеет форму $$C=\frac{1}{n}\sum_{x} C_x$$, где $$C_x\equiv \frac{ {\left \| y(x)-a \right \|}^2}{2}$$ – средние потери для каждого элемента обучающей выборки. На практике для вычисления градиента $$\nabla C$$, нам необходимо вычислить градиенты $$\nabla C_x$$ отдельно для каждого входа $$x$$, а затем усреднить их $$\nabla C = \frac {1}{n} \sum_{x} \nabla C_x$$. К сожалению, при большом объеме обучающей выборки это может занять много времени и увеличить время обучения.

Подход, называемый *стохастическим градиентным спуском*, может быть использован для ускорения обучения. Идея заключается в том, чтобы оценить градиент $$\nabla C$$ путем вычисления $$\nabla C_x$$ для небольшого количества примеров, случайно выбранных из обучающей выборки. Путем усреднения значений по этой небольшой выборке, можно быстро получить хорошую оценку истинного градиента $$\nabla C$$. Это поможет ускорить метод градиентного спуска и, соответственно, обучение.

Для придания большей строгости методу стохастического градиентного спуска, обозначим $$m$$ некоторое небольшое число случайно выбранных элементов обучающей выборки. Обозначим эти случайные элементы выборки $$X_1, X_2, ..., X_m$$. Такая случайная группа элементов называется *минибатчем*. При условии, что размер выборки $$m$$ достаточно велик, мы ожидаем, что среднее значение $$\nabla C_X_j$$ будет примерно равно среднему по всем $$\nabla C_x$$, то есть:

$$\frac {\sum_{j-1}^{m} \nabla C_X_j}{m} \approx \frac {\sum_{x}\nabla C_x}{n} = \nabla C$$

где вторая сумма берется по всей совокупности обучающей выборки. Таким образом, мы получаем:

$$\nabla C \approx \frac{1}{m}\sum_{j=1}^{m}\nabla C_X_j$$

получая подтверждение того, что можно оценить общий градиент путем вычисления градиентов только для случайно выбранного минибатча.

Теперь можно применить этот способ для обучения нейронных сетей. Предположим, что $$w_k$$ и $$b_l$$ обозначают веса и смещения в нашей нейронной сети. Тогда метод стохастического градиентного спуска работает путем выбора случайным образом минибатча из обучающей выборки и обучения по правилам:

$$w_k\rightarrow {w_k}'=w_k-\frac{\eta}{m}\sum_j\frac{\delta C_X_j}{\delta w_k}$$

$$b_l\rightarrow {b_l}'=b_l-\frac{\eta}{m}\sum_j\frac{\delta C_X_j}{\delta b_l}$$

где суммы идут по всем примерам из обучающей выборки текущего минибатча. Затем мы выбираем еще один случайный минибатч и обучаем таким же образом. И так далее, пока мы не перебрали все примеры из обучающей выборки, или, говоря иначе, завершили *эпоху* обучения. В этот момент мы начинаем все заново с новой эпохи.

Кстати, стоит отметить, что определения могут различаться в масштабе функции потерь и обновлений весов и смещений в минибатче. В уравнении (6) мы масштабируем общую функцию потерь на $$\frac{1}{n}$$. Люди иногда опускают $$\frac{1}{n}$$, суммируя потери для каждого элемента обучающей выборки вместо их усреднения. Это будет особенно полезным, если общее количество обучающей выборки заранее неизвестно. Такое случается, когда обучающая выборка собирается в режиме реального времени. Похожим способом изменяются правила обновления минибатча (20) и (21): иногда из правой части выражения опускают $$\frac{1}{m}$$. Вообще говоря, такая замена мало на что влияет, так как это эквивалентно изменению масштаба скорости обучения $$\eta$$. Но на это стоит обращать внимание при разборе других работ.

В качестве иллюстрации, мы можем считать метод стохастического градиентного спуска как своего рода опрос общественного мнения: гораздо проще использовать минибатчи, чем применять метод градиентного спуска ко всей выборке, так же, как и проведение опроса проще, чем организация полноценных выборов. Например, если у нас имеется обучающая выборка размера $$n=60000$$, как в MNIST, теперь выберем минибатч размера $$m=10$$. Это означает, что мы получим ускорение в $$6000$$ раз при оценке градиента! Конечно, оценка не будет точной, возможны статистические флуктуации, но нам не нужна такая точность: все что нам нужно – лишь двигаться в направлении уменьшения $$C$$. И это означает, что нам не нужно точное вычисление градиента. На практике метод стохастического градиентного спуска является широко используемым, это мощная техника для обучения нейронных сетей, и она является основой для большинства методов обучения, которые мы будем рассматривать в этой книге.

### Упражнения

Крайним случаем градиентного спуска будет являться использование минибатча размера $$1$$. То есть, имея вход $$x$$, мы обновляем веса и смещения в соответствии с правилами: $$w_k\rightarrow{w}'_k-\eta\delta C_x/\delta w_k$$ и $$ b_l\rightarrow{b}'_l-\eta\delta C_x/\delta b_l$$. Затем мы выбираем другие данные на вход из выборки и обновляем значения весов и смещений. И повторяем так далее. Эта процедура известна как онлайн- или инкрементальное обучение. В случае онлайн-обучения, нейронная сеть обучается только от одного примера одномоментно (как и люди). Назовите одно преимущество и один недостаток онлайн-обучения, по сравнению с методом стохастического градиентного спуска с размером минибатча, скажем, $$20$$.

В заключение этого раздела, позвольте мне разъяснить то, что кажется странным людям при знакомстве с методом градиентного спуска. В нейронных сетях функция потерь $$C$$ является, конечно, функцией многих переменных – всех весов и смещений. И поэтому в каком-то смысле она определяет поверхность с большим числом измерений. Некоторые люди могут зациклиться на этом: «Как я могу представить все эти измерения?». Они могут начать волноваться: «Я не могу вообразить четыре измерения, не говоря о пяти или пяти миллионах». Может существует какой-то способ, о котором они не знают, но который доступен для всех математиков? Конечно такого способа не существует. Большинство профессиональных математиков не способны хорошо представить четыре измерения, если способны вообще. Они используют другой подход вместо прямого представления. Именно этих мы и занимались выше: мы использовали алгебраическое (а не визуальное) представление $$\delta C$$, чтобы выяснить каким образом делать градиентный шаг для уменьшения значения $$C$$. Люди, хорошо представляющие высоко размерные пространства имеют особый склад мышления, который содержит множество различных способов подобных этому – алгебраический способ лишь один из них. Эти способы нелегки для восприятия, поскольку мы привыкли работать с тремя измерениями, но как только вы освоите коллекцию этих способов, то сможете получить довольно хорошее представление о многомерных пространствах. Некоторые из этих методов являются довольно сложными для восприятия, однако большая часть других будут интуитивно понятны и доступны для большинства.

## Реализация сети для классификации цифр

Итак, давайте напишем программу, которая обучается распознаванию рукописных цифр при помощи метода стохастического градиентного спуска и набор данных MNIST для обучения. Мы напишем короткую программу на языке Python (2.7) используя всего 74 строки кода! Для начала нам нужно получить набор данных MNIST. Если вы умеете обращаться с `git`, то можно получить данные путем клонирования репозитория кода для этой книги.

`git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git`

Если вы не используете `git`, то вы можете загрузить данные и код здесь.

Ранее, когда я описывал набор данных MNIST, я сказал, что этот набор состоит из 60000 образцов для обучения и 10000 тестовых изображений. Это официальное описание MNIST. Однако, мы собираемся разделить данные немного по-другому. Мы оставим тестовые образцы как есть, но разделим обучающую выборку MNIST из 60000 изображений на две части: набор из 50000 изображений, который будет использоваться для обучения нашей нейронной сети, а также отдельный набор из 10000 изображений для проверки, называемый *валидационной выборкой*. Мы не будем использовать валидационные данный в этой главе, но позднее в этой книге он нам понадобится для определения *гиперпараметров* нейронной сети – таких как скорость обучения и прочих, которые не могут быть подобраны непосредственно алгоритмом обучения. Несмотря на то, что валидационные данные не являются частью оригинальной спецификации MNIST, многие люди используют MNIST таким образом, и использование валидационных данных является общим подходом в нейронных сетях. Поэтому с этого момента, говоря о наборе данных MNIST, я буду ссылаться на наш набор данных из 50000 изображений, а не на оригинальный набор из 60000 изображений.